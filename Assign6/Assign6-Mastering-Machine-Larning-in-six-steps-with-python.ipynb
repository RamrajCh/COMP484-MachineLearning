{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPAroOBPY6in"
   },
   "source": [
    "# COMP 484 - Practical Assignment 6\n",
    "\n",
    "### Ramraj Chimouriya\n",
    "### CE IV / I\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ayN4MKRZTdB"
   },
   "source": [
    "## Book - Learning Machine learning in 6 steps\n",
    "\n",
    "## Chapter 6 - Deep and Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5x5z9LMZiyO"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iqr7yzUPZk20"
   },
   "source": [
    "### Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnDbOHOrZxYa"
   },
   "source": [
    "RNN has a feedback loop, which means it feeds previous time steps into\n",
    "the current step. This type of architecture generates sequences to simulate the situation\n",
    "and create synthetic data. This makes it the ideal modeling choice to work on sequence\n",
    "data such as speech text mining, image captioning, time series prediction, robot control,\n",
    "language modeling, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71cT_3jLcedH"
   },
   "source": [
    "### Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLEkWKivclwd"
   },
   "source": [
    "LSTM is an implementation of improved RNN architecture to address the issues of\n",
    "general RNN, and it enables long-range dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nZJBltWvZhnS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2017)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqMxx9-SdGHZ"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlVOjddOcwvl",
    "outputId": "ca13150c-d0f7-49c5-9217-ef4fe7b3a059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "17473536/17464789 [==============================] - 0s 0us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (25000, 80)\n",
      "X_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxqijP8FdRt0"
   },
   "source": [
    "#### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kaIFzTxGdNIC"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, recurrent_dropout=0.2, dropout=0.2))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlgsKuxsdaB4"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0CMjW4dGdU06",
    "outputId": "a49a16ba-58e0-42d0-b5ba-097b4e77efb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 134s 169ms/step - loss: 0.4301 - accuracy: 0.7988 - val_loss: 0.3913 - val_accuracy: 0.8252\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 131s 167ms/step - loss: 0.2562 - accuracy: 0.8972 - val_loss: 0.3770 - val_accuracy: 0.8349\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 129s 165ms/step - loss: 0.1641 - accuracy: 0.9378 - val_loss: 0.4675 - val_accuracy: 0.8274\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 129s 165ms/step - loss: 0.1055 - accuracy: 0.9617 - val_loss: 0.7038 - val_accuracy: 0.8092\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 129s 164ms/step - loss: 0.0735 - accuracy: 0.9740 - val_loss: 0.6880 - val_accuracy: 0.8135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19306e8150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_2cfEObkwiT"
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HixFpY2Xddz2",
    "outputId": "6369f0cf-c7a1-48fe-c4d4-a20c2708904b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0377 - accuracy: 0.9887\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.6880 - accuracy: 0.8135\n",
      "Train score: 0.03774108365178108\n",
      "Train accuracy: 0.9886800050735474\n",
      "Test score: 0.6879621744155884\n",
      "Test accuracy: 0.813480019569397\n"
     ]
    }
   ],
   "source": [
    "train_score, train_acc = model.evaluate(X_train, y_train, batch_size=batch_size)\n",
    "test_score, test_acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print ('Train score:', train_score)\n",
    "print ('Train accuracy:', train_acc)\n",
    "\n",
    "print ('Test score:', test_score)\n",
    "print ('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajvsTJlalIog"
   },
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMhlU2dvlK3h"
   },
   "source": [
    "Transfer learning is an area in ML that aims to utilize the knowledge gained while\n",
    "solving one problem to solve a different but related problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sCMKmneMkzhX"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSMflojRliRU"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "N6teej8nlfmn"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 5\n",
    "nb_epoch = 5\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "\n",
    "# size of pooling area for max pooling\n",
    "pool_size = 2\n",
    "\n",
    "# convolution kernel size\n",
    "kernel_size = 3\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cgOD7YYdlnXF",
    "outputId": "0d641381-15c3-4640-cf6e-8e1f80fc891c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# create two datasets one with digits below 5 and one with 5 and above\n",
    "X_train_lt5 = X_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "X_test_lt5 = X_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "X_train_gte5 = X_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5  # make classes start at 0 for\n",
    "X_test_gte5 = X_test[y_test >= 5]         # np_utils.to_categorical\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvqjiYOgmg8u"
   },
   "source": [
    "#### Train model for digits 0 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0rw5JW2glpVv"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train, test, nb_classes):\n",
    "    X_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    X_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(train[1], nb_classes)\n",
    "    Y_test = np_utils.to_categorical(test[1], nb_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size, epochs=nb_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O78oWB8Fmlbn",
    "outputId": "e9c10757-1c96-435c-c17f-bb7997d08e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Epoch 1/5\n",
      "240/240 [==============================] - 33s 136ms/step - loss: 1.6099 - accuracy: 0.2167 - val_loss: 1.5800 - val_accuracy: 0.3837\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 33s 136ms/step - loss: 1.5695 - accuracy: 0.3137 - val_loss: 1.5342 - val_accuracy: 0.5180\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 34s 140ms/step - loss: 1.5276 - accuracy: 0.4016 - val_loss: 1.4855 - val_accuracy: 0.6513\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 33s 136ms/step - loss: 1.4798 - accuracy: 0.4884 - val_loss: 1.4303 - val_accuracy: 0.7381\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 33s 136ms/step - loss: 1.4254 - accuracy: 0.5615 - val_loss: 1.3661 - val_accuracy: 0.8005\n",
      "Test score: 1.3661460876464844\n",
      "Test accuracy: 0.8005448579788208\n"
     ]
    }
   ],
   "source": [
    "# define two groups of layers: feature (convolutions) and classification (dense)\n",
    "feature_layers = [\n",
    "    Conv2D(nb_filters, kernel_size,\n",
    "                  padding='valid',\n",
    "                  input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(nb_filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(pool_size, pool_size)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(nb_classes),\n",
    "    Activation('softmax')\n",
    "]\n",
    "\n",
    "# create complete model\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "# train model for 5-digit classification [0..4]\n",
    "train_model(model, (X_train_lt5, y_train_lt5), (X_test_lt5, y_test_lt5), nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5i_TOSsxnUzR"
   },
   "source": [
    "#### Transfer existing trained model on 0 to 4 to build model for digits 5 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ZzzFoHimodY",
    "outputId": "a31efbc6-daa1-4de2-ca09-fd10904e3fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Epoch 1/5\n",
      "230/230 [==============================] - 11s 45ms/step - loss: 1.5912 - accuracy: 0.2632 - val_loss: 1.5573 - val_accuracy: 0.3874\n",
      "Epoch 2/5\n",
      "230/230 [==============================] - 9s 41ms/step - loss: 1.5557 - accuracy: 0.3055 - val_loss: 1.5199 - val_accuracy: 0.4536\n",
      "Epoch 3/5\n",
      "230/230 [==============================] - 9s 41ms/step - loss: 1.5204 - accuracy: 0.3642 - val_loss: 1.4827 - val_accuracy: 0.5421\n",
      "Epoch 4/5\n",
      "230/230 [==============================] - 9s 41ms/step - loss: 1.4878 - accuracy: 0.4242 - val_loss: 1.4459 - val_accuracy: 0.6377\n",
      "Epoch 5/5\n",
      "230/230 [==============================] - 9s 41ms/step - loss: 1.4559 - accuracy: 0.4757 - val_loss: 1.4102 - val_accuracy: 0.7060\n",
      "Test score: 1.4102023839950562\n",
      "Test accuracy: 0.7060275673866272\n"
     ]
    }
   ],
   "source": [
    "# freeze feature layers and rebuild model\n",
    "for layer in feature_layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# transfer: train dense layers for new classification task [5..9]\n",
    "train_model(model, (X_train_gte5, y_train_gte5), (X_test_gte5, y_test_gte5), nb_classes)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ML_Assign6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
