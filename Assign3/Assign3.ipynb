{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a7d8eb-803d-4d4c-ac1c-c27804e63891",
   "metadata": {},
   "source": [
    "# COMP 484 - Practical Assignment 3\n",
    "\n",
    "#### Ramraj Chimouriya\n",
    "#### CE IV/I\n",
    "\n",
    "## Chapter 6 - Clustering â€“ Finding Related Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b479ba-9c72-4e77-9929-0264f50719ed",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676c84-d01c-4e73-ac22-eb96d1ca4f88",
   "metadata": {},
   "source": [
    "### Converting raw test into a bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae900d1-5a48-4bdc-964f-bcbbf1686076",
   "metadata": {},
   "source": [
    "Scikit's CounterVectorizer method count words and represent those counts as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347c3acd-8f98-4f57-a396-1f4a12eb5211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca4c7f-0cfa-4ea1-87f2-89ad443964a7",
   "metadata": {},
   "source": [
    "Consider the following examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13af96b-4c33-47d8-9d97-8724b30ebad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['disk', 'format', 'hard', 'how', 'my', 'problems', 'to'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = [\"How to format my hard disk\",\n",
    "           \"Hard disk format problems\"]\n",
    "\n",
    "X = vectorizer.fit_transform(content)\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0efb0bdc-5d38-4f30-9ab4-8903e164ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79540dd-3a80-4adc-8df7-160c8685f8c0",
   "metadata": {},
   "source": [
    "### Counting words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a49cc5-c5de-46e6-8772-e6f0ba87aac1",
   "metadata": {},
   "source": [
    "Reading posts from data/toy directory and feeding to CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece17020-1a36-44de-bbff-22509df496e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "TOY_DIR = Path(\"data/toy\")\n",
    "posts = []\n",
    "for fn in TOY_DIR.iterdir():\n",
    "    with open(fn, 'r') as f:\n",
    "        posts.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef4b1620-cf60-4684-97ee-5dedfe2e3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b0f176-173b-41ae-9b0e-35d7fce8cf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 5 \t features:25\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(posts)\n",
    "num_samples, num_features = X_train.shape\n",
    "print(f\"samples: {num_samples} \\t features:{num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6049f9-7cc1-4654-a87b-814a7a4fa2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about' 'actually' 'capabilities' 'contains' 'data' 'databases' 'images'\n",
      " 'imaging' 'interesting' 'is' 'it' 'learning' 'machine' 'most' 'much'\n",
      " 'not' 'permanently' 'post' 'provide' 'save' 'storage' 'store' 'stuff'\n",
      " 'this' 'toy']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb867d-33ba-44d7-b56a-46dd96a4d270",
   "metadata": {},
   "source": [
    "Now, we can vectorize our new post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35223ca5-fb19-43c0-b565-c903932843de",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_post = \"Imaging databases\"\n",
    "new_post_vec = vectorizer.transform([new_post])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f212f91c-6a37-4d0e-abb9-906e6b632b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "print(new_post_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbd1be3-99e4-4c26-ac30-3a2093220146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(new_post_vec.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3fc4cf-8e16-4838-a23d-be9d103e5ff1",
   "metadata": {},
   "source": [
    "For the similarity measurement (the naive one), we calculate the Euclidean distance between the count vectors of the new post and all the old posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd682a27-215f-4427-8d81-4122bff4f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def dist_raw(v1, v2):\n",
    "    delta = v1-v2\n",
    "    return scipy.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f49898-0552-4650-80b9-b9046227c500",
   "metadata": {},
   "source": [
    "Function that takes the current dataset and the new post in vectorized form as well as a distance function and prints out an analysis of how well the distance function works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e69cc6b6-d934-4c6f-bca5-1e104aecb93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_post(X, new_vec, dist_func):\n",
    "    best_doc = None\n",
    "    best_dist = float('inf')    #infinite value as a starting point\n",
    "    best_i = None\n",
    "    for i, post in enumerate(posts):\n",
    "        if post == new_post:\n",
    "            continue\n",
    "        post_vec = X.getrow(i)\n",
    "        d = dist_func(post_vec, new_vec)\n",
    "        print(f\"=== Post {i} with dist={round(d,2)}: \\n'{post}'\")\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_i = i\n",
    "    print(f\"===> Best post is {best_i} with dist={round(best_dist,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80201f43-d108-4283-8014-35c964951741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=1.41: \n",
      "'Imaging databases store data.'\n",
      "=== Post 1 with dist=2.0: \n",
      "'Most imaging databases save images permanently.\n",
      "'\n",
      "=== Post 2 with dist=1.73: \n",
      "'Imaging databases provide storage capabilities.'\n",
      "=== Post 3 with dist=4.0: \n",
      "'This is a toy post about machine learning. Actually, it contains not much interesting stuff.'\n",
      "=== Post 4 with dist=5.1: \n",
      "'Imaging databases store data. Imaging databases store data. Imaging databases store data.'\n",
      "===> Best post is 0 with dist=1.41\n"
     ]
    }
   ],
   "source": [
    "best_post(X_train, new_post_vec, dist_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8b9a2-2c32-4112-a975-7cb06b1316be",
   "metadata": {},
   "source": [
    "### Normalizing word count vectors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29f79bf0-d611-4540-980c-085b74db612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_norm(v1, v2):\n",
    "    v1_normalized = v1 / scipy.linalg.norm(v1.toarray())\n",
    "    v2_normalized = v2 / scipy.linalg.norm(v2.toarray())\n",
    "    delta = v1_normalized - v2_normalized\n",
    "    return scipy.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5bcd5b9-564c-474d-b1c6-daa7412e9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=0.77: \n",
      "'Imaging databases store data.'\n",
      "=== Post 1 with dist=0.92: \n",
      "'Most imaging databases save images permanently.\n",
      "'\n",
      "=== Post 2 with dist=0.86: \n",
      "'Imaging databases provide storage capabilities.'\n",
      "=== Post 3 with dist=1.41: \n",
      "'This is a toy post about machine learning. Actually, it contains not much interesting stuff.'\n",
      "=== Post 4 with dist=0.77: \n",
      "'Imaging databases store data. Imaging databases store data. Imaging databases store data.'\n",
      "===> Best post is 0 with dist=0.77\n"
     ]
    }
   ],
   "source": [
    "best_post(X_train, new_post_vec, dist_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e536e-faea-44e6-81ee-4c10f8af7192",
   "metadata": {},
   "source": [
    "### Removing less important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "097707d8-0583-4b0e-94a4-490d9d6e910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_engl = CountVectorizer(min_df=1, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77a53e8f-48d3-4688-89a7-8e9152e42d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amoungst']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vect_engl.get_stop_words())[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9a31e82-5de1-4aaa-ab95-7cb437020aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 5, #features: 18\n",
      "['actually' 'capabilities' 'contains' 'data' 'databases' 'images'\n",
      " 'imaging' 'interesting' 'learning' 'machine' 'permanently' 'post'\n",
      " 'provide' 'save' 'storage' 'store' 'stuff' 'toy']\n"
     ]
    }
   ],
   "source": [
    "X_train_engl = vect_engl.fit_transform(posts)\n",
    "num_samples_engl, num_features_engl = X_train_engl.shape\n",
    "print(f\"#samples: {num_samples_engl}, #features: {num_features_engl}\")\n",
    "print(vect_engl.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4aa9a0c-cfb9-4742-8004-a29e221b31e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=0.77: \n",
      "'Imaging databases store data.'\n",
      "=== Post 1 with dist=0.86: \n",
      "'Most imaging databases save images permanently.\n",
      "'\n",
      "=== Post 2 with dist=0.86: \n",
      "'Imaging databases provide storage capabilities.'\n",
      "=== Post 3 with dist=1.41: \n",
      "'This is a toy post about machine learning. Actually, it contains not much interesting stuff.'\n",
      "=== Post 4 with dist=0.77: \n",
      "'Imaging databases store data. Imaging databases store data. Imaging databases store data.'\n",
      "===> Best post is 0 with dist=0.77\n"
     ]
    }
   ],
   "source": [
    "new_post_vec_engl = vect_engl.transform([new_post]) \n",
    "\n",
    "best_post(X_train_engl, new_post_vec_engl, dist_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec9698-6060-48e8-94c2-522e44cd9f0b",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f67d7fe-5510-4dfd-a287-702a7afb1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78661fe9-e254-482e-9d6b-fa81f76aefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51b419a8-c4dd-4d01-babe-7c9c90f823cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graphic'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"graphics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883b576-c04b-4fee-b8e2-71f26bc6607e",
   "metadata": {},
   "source": [
    "### Extending the vectorizer with NLTK's stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85eba24b-ffb7-4a1a-9648-d79ccb09eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stemmer = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42cd883e-7b3d-42d9-895f-ea9d1ed8cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec84f423-79b9-41c8-a42d-f7e7130bae13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StemmedCountVectorizer(stop_words='english')\n"
     ]
    }
   ],
   "source": [
    "vect_engl_stem = StemmedCountVectorizer(min_df=1, stop_words='english')\n",
    "print(vect_engl_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "deb7ce53-467f-4f3d-aa08-a9ae39d95a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 5, #features: 17\n",
      "['actual', 'capabl', 'contain', 'data', 'databas', 'imag', 'interest', 'learn', 'machin', 'perman', 'post', 'provid', 'save', 'storag', 'store', 'stuff', 'toy']\n"
     ]
    }
   ],
   "source": [
    "X_train_engl_stem = vect_engl_stem.fit_transform(posts)\n",
    "num_samples_engl_stem, num_features_engl_stem = X_train_engl_stem.shape\n",
    "print(f\"#samples: {num_samples_engl_stem}, #features: {num_features_engl_stem}\")\n",
    "print(vect_engl_stem.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1f196-13f2-4e7f-ab7a-4c006d7ea755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
